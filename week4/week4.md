#### Before Week 4:
- Read [chapter 6](http://www.nltk.org/book_1ed/ch06.html) of _Natural Language Processing with Python_
- Watch **Text Classification**:
    + [What is Text Classification](https://class.coursera.org/nlp/lecture/36)
    + [Naive Bayes](https://class.coursera.org/nlp/lecture/37)
    + [Formalizing the Naive Bayes Classifier](https://class.coursera.org/nlp/lecture/25)
    + [Naive Bayes: Learning](https://class.coursera.org/nlp/lecture/26)
    + [Naive Bayes: Relationship to Language Modeling](https://class.coursera.org/nlp/lecture/27)
    + [Multinomial Naive Bayes: A Worked Example](https://class.coursera.org/nlp/lecture/28)
    + [Precision, Recall, and the F measure](https://class.coursera.org/nlp/lecture/142)
    + [Text Classification: Evaluation](https://class.coursera.org/nlp/lecture/143)
    + [Practical Issues in Text Classification](https://class.coursera.org/nlp/lecture/29)  

1. Monday 6/15: **Text Classification**
    - Before Tuesday:
        + Watch **Sentiment Analysis**:
            * [What is Sentiment Analysis?](https://class.coursera.org/nlp/lecture/31)
            * [Sentiment Analysis- A baseline algorithm](https://class.coursera.org/nlp/lecture/145)
            * [Sentiment Lexicons](https://class.coursera.org/nlp/lecture/35)
            * [Learning Sentiment Lexicons](https://class.coursera.org/nlp/lecture/144)
            * [Other Sentiment Tasks](https://class.coursera.org/nlp/lecture/33)
        + Optional Reading:
            * [Thumbs up? Sentiment Classification using Machine Learning Techniques](http://www.cs.cornell.edu/home/llee/papers/sentiment.pdf) (recommended)
            * [General Inquirer](http://www.wjh.harvard.edu/~inquirer)
            * [Christopher Potts' Sentiment Tutorial](http://sentiment.christopherpotts.net/)
            * [On the Negativity of Negation](http://web.stanford.edu/~cgpotts/papers/potts-salt20-negation.pdf)
2. Tuesday 6/16: **Sentiment Analysis**
    - Before Thursday:
        + Watch **Discriminative Classifiers**
            * [Generative vs. Discriminative Models](https://class.coursera.org/nlp/lecture/38)
            * [Making features from text for discriminative NLP models](https://class.coursera.org/nlp/lecture/48)
            * [Feature-Based Linear Classifiers](https://class.coursera.org/nlp/lecture/51)
            * [Building a Maxent Model: The Nuts and Bolts](https://class.coursera.org/nlp/lecture/53)
            * [Generative vs. Discriminative models: The problem of overcounting evidence](https://class.coursera.org/nlp/lecture/131)
            * [Maximizing the Likelihood](https://class.coursera.org/nlp/lecture/134)
4. Thursday 6/18: **Logistic Regression (a.k.a. MaxEnt)**
    - Before Friday:
        + Watch **[Topic Modeling](https://www.dropbox.com/s/tpgede8s57fvmxp/nmf-video.mov)**
3. Friday 6/19: **Topic Modeling and NMF**

#### Before Week 5:
- Read [chapter 7](http://www.nltk.org/book_1ed/ch07.html) of _Natural Language Processing with Python_
- Watch **Information Extraction and Sequence Modeling**:
    + [Introduction to Information Extraction](https://class.coursera.org/nlp/lecture/61)
    + [Evaluation of Named Entity Recognition](https://class.coursera.org/nlp/lecture/132)
    + [Sequence Models for Named Entity Recognition](https://class.coursera.org/nlp/lecture/59)
    + [Maximum Entropy Sequence Models](https://class.coursera.org/nlp/lecture/133)