#### Before Week 5:
+ Prepare data for Tuesday's Lab:
    1. Get at least 1000 articles from api.nytimes.com
    2. Scrape these articles from the web and store the content in Mongo (hint: `soup.find_all('p', itemprop='articleBodyâ€™)`)
    3. Tokenize and tag them and store the results in Mongo (along with the original text)
    4. Optional (but highly recommended) rerun section classification and topic modeling on these data. 
+ Read [chapter 7](http://www.nltk.org/book_1ed/ch07.html) of _Natural Language Processing with Python_
+ Watch **Information Extraction and Sequence Modeling**:
    * [Introduction to Information Extraction](https://class.coursera.org/nlp/lecture/61)
    * [Evaluation of Named Entity Recognition](https://class.coursera.org/nlp/lecture/132)
    * [Sequence Models for Named Entity Recognition](https://class.coursera.org/nlp/lecture/59)
    * [Maximum Entropy Sequence Models](https://class.coursera.org/nlp/lecture/133)
+ Optional: 
    * [Linguistic Data Consortium](https://www.ldc.upenn.edu/)
    * [Conditional Random Fields: Probabilistic Models for Segmenting and Labeling Sequence Data](http://repository.upenn.edu/cgi/viewcontent.cgi?article=1162&context=cis_papers)
    * [ACE (Automatic Content Extraction) English Annotation Guidelines for Entities](https://www.ldc.upenn.edu/sites/www.ldc.upenn.edu/files/english-entities-guidelines-v6.6.pdf)

1. Monday 6/22: **Named Entity Recognition**
    - Before Class:
        - Watch:
            - [The Maximum Entropy Model Presentation](https://class.coursera.org/nlp/lecture/148)
            - [Feature Overlap-Feature Interaction](https://class.coursera.org/nlp/lecture/135)
            - [Conditional Maxent Models for Classification](https://class.coursera.org/nlp/lecture/147)
            - [Smoothing-Regularization-Priors for Maxent Models](https://class.coursera.org/nlp/lecture/136)
3. Thursday 6/25: **Advanced Maximum Entropy Models**
    - Before Class:
        - Watch:
            - [What is Relation Extraction?](https://class.coursera.org/nlp/lecture/138)
            - [Using Patterns to Extract Relations](https://class.coursera.org/nlp/lecture/139)
            - [Supervised Relation Extraction](https://class.coursera.org/nlp/lecture/140)
            - [Semi-Supervised and Unsupervised Relation Extraction](https://class.coursera.org/nlp/lecture/141)
        + Optional: 
            * [Automatic Acquisition of Hyponyms from Large Text Corpora](http://acl-arc.comp.nus.edu.sg/archives/acl-arc-090501d3/data/pdf/anthology-PDF/C/C92/C92-2082.pdf)
            * [Extracting Patterns and Relations from the World Wide Web](http://ilpubs.stanford.edu:8090/421/1/1999-65.pdf)
2. Tuesday 6/23: **Relation Extraction**
    - Before Class:
        - Watch:
            - [Syntactic Structure: Constituency vs Dependency](https://class.coursera.org/nlp/lecture/161)
            - [Empirical-Data-Driven Approach to Parsing](https://class.coursera.org/nlp/lecture/162)
            - [The Exponential Problem in Parsing](https://class.coursera.org/nlp/lecture/163)
4. Friday 6/26: **Parsing Introduction**

#### For Week 6:
- Before Monday:
    + Read [chapter 8](http://www.nltk.org/book_1ed/ch08.html) of _Natural Language Processing with Python_
    + Watch **Information Extraction and Sequence Modeling**:
        * [CFGs and PCFGs](https://class.coursera.org/nlp/lecture/165)
        * [Grammar Transforms](https://class.coursera.org/nlp/lecture/166)
        * [CKY Parsing](https://class.coursera.org/nlp/lecture/167)
        * [CKY Example](https://class.coursera.org/nlp/lecture/168)
        * [Constituency Parser Evaluation](https://class.coursera.org/nlp/lecture/169)
